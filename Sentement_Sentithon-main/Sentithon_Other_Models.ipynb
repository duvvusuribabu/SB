{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLRVhXnUtZyIsXiZ3WLPtK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BALU2000-creator/Sentement_Sentithon/blob/main/Sentithon_Other_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**text**-**davinci-003** **bold text**(Transformer model) from open-AI"
      ],
      "metadata": {
        "id": "c3CDfIGh1wub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "sDswksLh2V48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Classify the sentiment in these tweets:\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored üò†\\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable ‚ù§Ô∏è‚ù§Ô∏è\\\"\\n5. \\\"I hate chocolate\\\"\\n\\nTweet sentiment ratings:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")"
      ],
      "metadata": {
        "id": "-LytPLLs1wZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NavieBayes Model. \n",
        "Extract this data  and use. However this is not the best model to do and not recommended.\n",
        "https://drive.google.com/drive/folders/1Cx3ELsDLdTsCjFatVmsVUNz2yMYj1aJe?usp=share_link\n",
        "\n"
      ],
      "metadata": {
        "id": "VVScfO-7vE04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzg_ndmoq76O"
      },
      "outputs": [],
      "source": [
        "import math \n",
        "import os, string, re\n",
        "from functools import reduce\n",
        "_NINF = float('-1e300')\n",
        "\n",
        "class Probdist:\n",
        "  def __init__(self, freqdist, gamma=0.5, bins=None):\n",
        "    self._gamma = gamma\n",
        "    self._freqdist = freqdist\n",
        "    n = sum(freqdist.values())\n",
        "    self._bins = len(freqdist) if bins is None else bins\n",
        "    self._divisor = n + self._bins*self._gamma\n",
        "    # print(self._divisor)\n",
        "\n",
        "  def prob(self, sample):\n",
        "    c = self._freqdist.get(sample, 0) + self._gamma\n",
        "    return c/self._divisor\n",
        "\n",
        "  def logprob(self, sample):\n",
        "    p = self.prob(sample)\n",
        "    return math.log(p, 2) if p!=0 else _NINF\n",
        "\n",
        "  def samples(self):\n",
        "    return self._freqdist.keys()\n",
        "\n",
        "class Naviebayes_Spam_classifier:\n",
        "  def __init__(self, train_folder='/content/train'):\n",
        "    self.train_folder = train_folder\n",
        "    self.spam_word_frequencies = self.frequency_finder(os.path.join(train_folder, 'spam'))\n",
        "    self.spam_word_probdist = Probdist(self.spam_word_frequencies)\n",
        "    self.ham_word_frequencies = self.frequency_finder(os.path.join(train_folder, 'notspam'))\n",
        "    self.ham_word_probdist = Probdist(self.ham_word_frequencies)\n",
        "    self.class_freq = {'Negative' : len(self.spam_word_frequencies), 'Positive' : len(self.ham_word_frequencies)}\n",
        "    self.class_probdist = Probdist(self.class_freq)\n",
        "\n",
        "  def read_file(self, documents_path, document):\n",
        "    with open(os.path.join(documents_path, document), 'r',encoding='ISO-8859-1') as f:\n",
        "      line = f.read()\n",
        "      line = re.sub(\"[\\t\\n\\<\\>\\/]\", \" \", line.lower())\n",
        "      line = re.sub(\"[\\']\", \"\", line)\n",
        "      line = re.sub(\"(--)*\", \"\", line) \n",
        "      line = re.sub(\"(--)*(_)*(=)*\", \"\", line)\n",
        "      line = re.sub('!#$%&()+./:;<=>?@^_`{|}~', '', line)\n",
        "    return line\n",
        "\n",
        "  def frequency_finder(self, documents_path):\n",
        "    word_frequencies = {}\n",
        "    documents = os.listdir(documents_path)\n",
        "    for document in documents:\n",
        "      line = self.read_file(documents_path, document) \n",
        "      list_of_words = line.split()\n",
        "      for i in list_of_words:\n",
        "        word_frequencies[i] = word_frequencies.get(i, 0) + 1\n",
        "    return word_frequencies\n",
        "\n",
        "  def test_model(self, test_data_path='/content/test'):\n",
        "    documents = os.listdir(test_data_path)\n",
        "    for document in documents:\n",
        "      all_spam_logs, all_ham_logs = [], []\n",
        "      line = self.read_file(test_data_path, document) \n",
        "      list_of_words = line.split()\n",
        "      for word in list_of_words:\n",
        "        spam_logprob, ham_logprob = self.spam_word_probdist.logprob(word), self.ham_word_probdist.logprob(word)\n",
        "        all_spam_logs.append(spam_logprob)\n",
        "        all_ham_logs.append(ham_logprob)\n",
        "      P_spam, P_ham = self.class_probdist.logprob('Negative')+sum(all_spam_logs), self.class_probdist.logprob('Positive')+sum(all_ham_logs)\n",
        "      liklihood = P_spam/P_spam\n",
        "      print((document, \"Negative\") if max(P_spam, P_ham)==P_spam else (document, \"Positive\"))\n",
        "\n",
        "  def __del__(self):\n",
        "    self.spam_word_frequencies.clear()\n",
        "    del self.spam_word_probdist\n",
        "    self.ham_word_frequencies.clear()\n",
        "    del self.ham_word_probdist\n",
        "    self.class_freq.clear()\n",
        "    del self.class_probdist\n",
        "\n",
        "    print('Destructor called, all deleted')\n",
        "\n",
        "Naviebayes_classifier = Naviebayes_Spam_classifier()\n",
        "Naviebayes_classifier.test_model()\n",
        "del Naviebayes_classifier"
      ]
    }
  ]
}